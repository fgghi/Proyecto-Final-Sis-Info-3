{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bd37f925-9934-4d59-a6b6-08f95cee7d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\comad\\anaconda3\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\comad\\anaconda3\\lib\\site-packages (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\comad\\anaconda3\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\comad\\anaconda3\\lib\\site-packages (from requests) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\comad\\anaconda3\\lib\\site-packages (from requests) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\comad\\anaconda3\\lib\\site-packages (from requests) (2023.11.17)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\comad\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35d1c8a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting geopy\n",
      "  Downloading geopy-2.4.1-py3-none-any.whl (125 kB)\n",
      "                                              0.0/125.4 kB ? eta -:--:--\n",
      "     ---------                               30.7/125.4 kB 1.4 MB/s eta 0:00:01\n",
      "     ---------------------------           92.2/125.4 kB 871.5 kB/s eta 0:00:01\n",
      "     -------------------------------------- 125.4/125.4 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting geographiclib<3,>=1.52 (from geopy)\n",
      "  Downloading geographiclib-2.0-py3-none-any.whl (40 kB)\n",
      "                                              0.0/40.3 kB ? eta -:--:--\n",
      "     ---------------------------------------- 40.3/40.3 kB 1.9 MB/s eta 0:00:00\n",
      "Installing collected packages: geographiclib, geopy\n",
      "Successfully installed geographiclib-2.0 geopy-2.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "731500d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def obtener_coordenadas(ciudad, pais):\n",
    "    geolocalizador = Nominatim(user_agent=\"myGeocoder\")\n",
    "    direccion = f\"{ciudad}, {pais}\"\n",
    "    ubicacion = geolocalizador.geocode(direccion)\n",
    "    \n",
    "    if ubicacion:\n",
    "        return ubicacion.latitude, ubicacion.longitude\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "def extraer_datos_ciudades(soup):\n",
    "    ciudades = {\"type\": \"FeatureCollection\", \"features\": []}\n",
    "\n",
    "    for ciudad_element in soup.find_all('h3'):\n",
    "        nombre_ciudad_match = re.search(r'<a.*?>(.*?)<\\/a>', str(ciudad_element))\n",
    "        nombre_ciudad = nombre_ciudad_match.group(1) if nombre_ciudad_match else \"No encontrado\"\n",
    "\n",
    "        pais_match = re.search(r'<a.*?>(.*?)<\\/a>,\\s(.*?)\\s\\(', str(ciudad_element))\n",
    "        pais = pais_match.group(2) if pais_match else \"No encontrado\"\n",
    "\n",
    "        poblacion_element = ciudad_element.find_next('p', string=re.compile('Población 2023'))\n",
    "        poblacion_2023 = \"\"\n",
    "        if poblacion_element:\n",
    "            next_element = poblacion_element.find_next_sibling('p')\n",
    "            if next_element:\n",
    "                poblacion_text = next_element.get_text()\n",
    "                poblacion_2023_match = re.search(r'([\\d,]+)\\s+\\(Variación', poblacion_text)\n",
    "                poblacion_2023 = poblacion_2023_match.group(1).replace(\",\", \"\") if poblacion_2023_match else \"No se encontró\"\n",
    "\n",
    "        if nombre_ciudad != \"No encontrado\" and pais != \"No encontrado\":\n",
    "            latitud, longitud = obtener_coordenadas(nombre_ciudad, pais)\n",
    "            ciudad = {\n",
    "                \"type\": \"Feature\",\n",
    "                \"geometry\": {\n",
    "                    \"type\": \"Point\",\n",
    "                    \"coordinates\": [longitud, latitud]\n",
    "                },\n",
    "                \"properties\": {\n",
    "                    \"Nombre\": nombre_ciudad,\n",
    "                    \"País\": pais,\n",
    "                    \"Población 2023\": poblacion_2023\n",
    "                }\n",
    "            }\n",
    "            ciudades[\"features\"].append(ciudad)\n",
    "    \n",
    "    return ciudades\n",
    "\n",
    "def guardar_datos_json(ciudades):\n",
    "    with open(\"datos_ciudades.json\", \"w\", encoding=\"utf-8\") as geojson_file:\n",
    "        json.dump(ciudades, geojson_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.archdaily.cl/cl/1003731/estas-son-las-ciudades-mas-pobladas-de-america-latina-en-2023\"\n",
    "\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    ciudades = extraer_datos_ciudades(soup)\n",
    "    guardar_datos_json(ciudades)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8b76070",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de la ciudad: Sao Paulo\n",
      "Población en 2023: 22619736\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Ciudad de México\n",
      "Población en 2023: 22281442\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Buenos Aires\n",
      "Población en 2023: 15490415\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Río de Janeiro\n",
      "Población en 2023: 11507960\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Lima\n",
      "Población en 2023: 6903392\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Belo Horizonte\n",
      "Población en 2023: 6247889\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Guadalajara\n",
      "Población en 2023: 5419880\n",
      "--------------------------------------\n",
      "Nombre de la ciudad: Monterrey\n",
      "Población en 2023: 5116647\n",
      "--------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "\n",
    "url = \"https://www.archdaily.cl/cl/1003731/estas-son-las-ciudades-mas-pobladas-de-america-latina-en-2023\"\n",
    "\n",
    "# Obtener el contenido HTML de la página\n",
    "response = requests.get(url)\n",
    "html_content = response.text\n",
    "\n",
    "# Expresión regular para extraer la información de población\n",
    "city_population_pattern = r'<h3>\\d+° - <a href=\".*?\">(.*?)<\\/a>,.*?<strong>Población 2023: <\\/strong>(.*?)\\s.*?'\n",
    "\n",
    "# Encontrar coincidencias en el HTML\n",
    "matches = re.findall(city_population_pattern, html_content, re.DOTALL)\n",
    "\n",
    "# Lista para almacenar los datos de las ciudades\n",
    "ciudades = []\n",
    "\n",
    "# Función para limpiar la información de población\n",
    "def clean_population_info(population):\n",
    "    population = population.replace(\",\", \"\")  # Eliminar comas\n",
    "    population = re.sub(r'<[^>]*>', '', population)  # Eliminar etiquetas HTML\n",
    "    return population.strip()\n",
    "\n",
    "# Iterar sobre las coincidencias encontradas\n",
    "for match in matches:\n",
    "    city_name = match[0]\n",
    "    population_2023 = clean_population_info(match[1])\n",
    "\n",
    "    ciudad_data = {\n",
    "        \"Nombre\": city_name,\n",
    "        \"Población 2023\": population_2023,\n",
    "    }\n",
    "    ciudades.append(ciudad_data)\n",
    "\n",
    "# Imprimir los resultados obtenidos con expresiones regulares\n",
    "for ciudad in ciudades:\n",
    "    print(f\"Nombre de la ciudad: {ciudad['Nombre']}\")\n",
    "    print(f\"Población en 2023: {ciudad['Población 2023']}\")\n",
    "    print(\"--------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c197021",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
